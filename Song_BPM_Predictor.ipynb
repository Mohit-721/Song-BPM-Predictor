{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tChldEeOb4H5"
      },
      "source": [
        "SONG BEATS PER MINUTE PREDICTION (Regression Pipeline)  \n",
        "Author: Mohit Kumar  \n",
        "Date: 2025-09-09"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QWQISUnwb8QN"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- 1. IMPORTS ---\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "# --- 1. IMPORTS ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehNVxN31cCOG"
      },
      "outputs": [],
      "source": [
        "# --- 2. DATA LOADING & SUMMARY ---\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "print(\"Shape :\", df.shape)\n",
        "print(\"\\nMissing values:\\n\", df.isnull().sum())\n",
        "print(\"\\nDescriptive Stats:\\n\", df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-1SHRkwcD1d"
      },
      "source": [
        "Observation: No missing values found, and 524,164 rows x 11 columns loaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZPtz6FUcOhS"
      },
      "outputs": [],
      "source": [
        "# --- 3. EXPLORATORY DATA ANALYSIS (EDA) ---\n",
        "\n",
        "# 3.1: Target distribution\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.histplot(df['BeatsPerMinute'], bins=50, kde=True)\n",
        "plt.title('Distribution of BeatsPerMinute')\n",
        "plt.xlabel('BPM')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnaQ0gVmcRBI"
      },
      "source": [
        "Observation: BPM distributes mainly between 80 and 160, with a few high outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFbxpIAycZy5"
      },
      "outputs": [],
      "source": [
        "# 3.2: Feature distributions (first 5 features)\n",
        "numeric_cols = df.select_dtypes(include=['float64', 'int']).columns.drop(['id'])\n",
        "for col in numeric_cols[:5]:\n",
        "    plt.figure(figsize=(6, 2))\n",
        "    sns.histplot(df[col], bins=40, kde=True)\n",
        "    plt.title(col)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1Ci5Gk6cdRv"
      },
      "outputs": [],
      "source": [
        "# 3.3: Correlation heatmap\n",
        "corr = df.corr()\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(corr[['BeatsPerMinute']].sort_values(by='BeatsPerMinute', ascending=False), annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation with BeatsPerMinute')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOQYYBrXcgC5"
      },
      "source": [
        "Observation: Energy and RhythmScore appear most correlated with BPM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAVOwGqVchw2"
      },
      "outputs": [],
      "source": [
        "# --- 4. FEATURE/TARGET SEPARATION & TRAIN-VALIDATION SPLIT ---\n",
        "x = df.drop(['id', 'BeatsPerMinute'], axis=1)\n",
        "y = df['BeatsPerMinute']\n",
        "print(\"Features shape:\", x.shape)\n",
        "print(\"Target shape:\", y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlbi_2tscjtA"
      },
      "outputs": [],
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "print(\"X_train shape:\", x_train.shape)\n",
        "print(\"X_val shape:\", x_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNfIk4iJcmvN"
      },
      "outputs": [],
      "source": [
        "# --- FEATURE SCALING ---\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_val_scaled = scaler.transform(x_val)\n",
        "print(\"Scaled Training shape:\", x_train_scaled.shape)\n",
        "print(\"Scaled Validation shape:\", x_val_scaled.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4ntM3aVcnqJ"
      },
      "outputs": [],
      "source": [
        "# --- 5. MODEL TRAINING & EVALUATION ---\n",
        "\n",
        "# 5.1 Linear Regression\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(x_train_scaled, y_train)\n",
        "y_val_pred = lr_model.predict(x_val_scaled)\n",
        "mae_lr = mean_absolute_error(y_val, y_val_pred)\n",
        "rmse_lr = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
        "print(f\"[Linear Regression] Validation MAE: {mae_lr:.4f}\")\n",
        "print(f\"[Linear Regression] Validation RMSE: {rmse_lr:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "It0tMScOcqXs"
      },
      "outputs": [],
      "source": [
        "# 5.2 Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42, n_jobs=-1)\n",
        "rf_model.fit(x_train_scaled, y_train)\n",
        "y_val_pred_rf = rf_model.predict(x_val_scaled)\n",
        "mae_rf = mean_absolute_error(y_val, y_val_pred_rf)\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_val, y_val_pred_rf))\n",
        "print(f\"[Random Forest] Validation MAE: {mae_rf:.4f}\")\n",
        "print(f\"[Random Forest] Validation RMSE: {rmse_rf:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C01wY8Gmc3gm"
      },
      "outputs": [],
      "source": [
        "# 5.3 Gradient Boosting Regressor\n",
        "gb_model = GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
        "gb_model.fit(x_train_scaled, y_train)\n",
        "y_val_pred_gb = gb_model.predict(x_val_scaled)\n",
        "mae_gb = mean_absolute_error(y_val, y_val_pred_gb)\n",
        "rmse_gb = np.sqrt(mean_squared_error(y_val, y_val_pred_gb))\n",
        "print(f\"[Gradient Boosting] Validation MAE: {mae_gb:.4f}\")\n",
        "print(f\"[Gradient Boosting] Validation RMSE: {rmse_gb:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dVHahzuc69Q"
      },
      "outputs": [],
      "source": [
        "# --- 6. MODEL COMPARISON SUMMARY ---\n",
        "print(\"\\n**MODEL COMPARISON TABLE**\")\n",
        "print(f\"Linear Regression   MAE: {mae_lr:.4f}  RMSE: {rmse_lr:.4f}\")\n",
        "print(f\"Random Forest       MAE: {mae_rf:.4f}  RMSE: {rmse_rf:.4f}\")\n",
        "print(f\"Gradient Boosting   MAE: {mae_gb:.4f}  RMSE: {rmse_gb:.4f}\")\n",
        "print(\"\\nObservation: Linear Regression and Gradient Boosting performed almost identically and best, suggesting data is quite linear or more advanced models need heavier tuning.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bdq34NbkdB0w"
      },
      "outputs": [],
      "source": [
        "# --- 7. RETRAIN FINAL (BEST) MODEL ON ALL TRAINING DATA & PREPARE SUBMISSION ---\n",
        "# Using Gradient Boosting here based on validation performance\n",
        "\n",
        "x_full = x\n",
        "y_full = y\n",
        "x_full_scaled = scaler.fit_transform(x_full)\n",
        "gb_model_final = GradientBoostingRegressor(n_estimators=50, max_depth=5, random_state=42)\n",
        "gb_model_final.fit(x_full_scaled, y_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlZZF0NjdEPI"
      },
      "outputs": [],
      "source": [
        "# --- 8. PREDICT ON TEST DATA ---\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "test_ids = test_df['id']\n",
        "x_test = test_df.drop(['id'], axis=1)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "test_preds = gb_model_final.predict(x_test_scaled)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'ID': test_ids,\n",
        "    'BeatsPerMinute': test_preds\n",
        "})\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"\\n[INFO] submission.csv created successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o01rzKZdGpr"
      },
      "source": [
        " --- 9. PROJECT REFLECTION / CONCLUSION ---\n",
        "1. In this project, I explored a large music dataset and built regression models to predict BeatsPerMinute.\n",
        "2. Visualization of distributions and correlations helped in understanding the data.\n",
        "3. Three models (Linear Regression, Random Forest, Gradient Boosting) were compared for accuracy.\n",
        "3. Gradient Boosting and Linear Regression achieved the best MAE/RMSE scores, showing the data's relationships are mostly linear.\n",
        "4. For larger datasets or faster training, I would consider GPU-accelerated models (XGBoost/LightGBM)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
